import asyncio
import json
from typing import TypedDict, Dict, Any
import httpx
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage
from langchain_core.prompts import PromptTemplate

from langgraph.graph import StateGraph, END
from langchain_ollama import ChatOllama, OllamaEmbeddings

# ==================================================
# TECH CATEGORIES
# ==================================================

TECH_CATEGORIES = [
    "Python-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫",
    "ML-–∏–Ω–∂–µ–Ω–µ—Ä",
    "Data Scientist",
    "Backend-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫",
    "Frontend-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫",
    "DevOps-–∏–Ω–∂–µ–Ω–µ—Ä",
]

# ==================================================
# STATE
# ==================================================

class AgentState(TypedDict):
    description: str
    job_type: str
    search_type: str
    category: str
    hh_stats: Dict[str, Any]
    rag_context: str
    confidence: Dict[str, float]
    processed: bool

# ==================================================
# MULTI AGENT SYSTEM
# ==================================================

class MultiAgentSystem:
    def __init__(self):
        # LLM
        self.llm = ChatOllama(
            model="qwen2.5:32b",
            base_url="http://localhost:11434",
            temperature=0.1
        )

        # Embeddings
        self.embeddings = OllamaEmbeddings(
            model="nomic-embed-text",
            base_url="http://localhost:11434"
        )

        # Vector DB (local)
        self.vectorstore = Chroma(
            collection_name="hh_vacancies",
            embedding_function=self.embeddings,
            persist_directory="./hh_chroma"
        )

        # Graph
        self.graph = self._build_graph()

    # --------------------------------------------------
    # GRAPH
    # --------------------------------------------------

    def _build_graph(self):
        g = StateGraph(AgentState)

        g.add_node("hr_agent", self.hr_agent)
        g.add_node("tech_agent", self.tech_agent)
        g.add_node("hh_agent", self.hh_agent)
        g.add_node("rag_agent", self.rag_agent)
        g.add_node("finalize", self.finalize)

        g.set_entry_point("hr_agent")
        g.add_edge("hr_agent", "tech_agent")
        g.add_edge("tech_agent", "hh_agent")
        g.add_edge("hh_agent", "rag_agent")
        g.add_edge("rag_agent", "finalize")
        g.add_edge("finalize", END)

        return g.compile()

    # --------------------------------------------------
    # HR AGENT
    # --------------------------------------------------

    async def hr_agent(self, state: AgentState) -> Dict[str, Any]:
        prompt = PromptTemplate(
            input_variables=["text"],
            template="""
–¢—ã HR-—ç–∫—Å–ø–µ—Ä—Ç.

–û–ø–∏—Å–∞–Ω–∏–µ:
{text}

–û—Ç–≤–µ—Ç—å JSON:
{{
  "job_type": "–ø—Ä–æ–µ–∫—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞ | –ø–æ—Å—Ç–æ—è–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞",
  "search_type": "–ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç—ã | –ø–æ–∏—Å–∫ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è"
}}
"""
        )

        res = await self.llm.ainvoke([
            HumanMessage(content=prompt.format(text=state["description"]))
        ])

        try:
            return json.loads(res.content)
        except Exception:
            return {
                "job_type": "–ø–æ—Å—Ç–æ—è–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞",
                "search_type": "–ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç—ã"
            }

    # --------------------------------------------------
    # TECH AGENT
    # --------------------------------------------------

    async def tech_agent(self, state: AgentState) -> Dict[str, Any]:
        cats = "\n".join(f"- {c}" for c in TECH_CATEGORIES)

        prompt = PromptTemplate(
            input_variables=["text", "cats"],
            template="""
–¢—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —ç–∫—Å–ø–µ—Ä—Ç.

–û–ø–∏—Å–∞–Ω–∏–µ:
{text}

–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:
{cats}

–í—ã–±–µ—Ä–∏ –û–î–ù–£ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ –Ω–∞–ø–∏—à–∏ –µ—ë —Ç–æ—á–Ω–æ.
"""
        )

        res = await self.llm.ainvoke([
            HumanMessage(content=prompt.format(
                text=state["description"],
                cats=cats
            ))
        ])

        cat = res.content.strip()
        if cat not in TECH_CATEGORIES:
            cat = TECH_CATEGORIES[0]

        return {"category": cat}

    # --------------------------------------------------
    # HH AGENT (LOAD DATA + RAG)
    # --------------------------------------------------

    async def hh_agent(self, state: AgentState) -> Dict[str, Any]:
        query = state["category"]

        async with httpx.AsyncClient(timeout=20) as client:
            r = await client.get(
                "https://api.hh.ru/vacancies",
                params={
                    "text": query,
                    "area": 113,  # –†–æ—Å—Å–∏—è
                    "per_page": 30
                },
                headers={"User-Agent": "HH-RAG-Agent"}
            )

        data = r.json()
        items = data.get("items", [])

        docs = []
        salaries = []

        for v in items:
            content = f"""
–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏: {v.get('name')}
–ö–æ–º–ø–∞–Ω–∏—è: {v.get('employer', {}).get('name')}
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: {v.get('snippet', {}).get('requirement')}
–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏: {v.get('snippet', {}).get('responsibility')}
–°—Å—ã–ª–∫–∞: {v.get('alternate_url')}
"""
            docs.append(Document(page_content=content))

            if v.get("salary") and v["salary"].get("from"):
                salaries.append(v["salary"]["from"])

        if docs:
            self.vectorstore.add_documents(docs)
            self.vectorstore.persist()

        avg_salary = sum(salaries) / len(salaries) if salaries else None

        return {
            "hh_stats": {
                "query": query,
                "found": data.get("found", 0),
                "avg_salary": avg_salary
            }
        }

    # --------------------------------------------------
    # RAG AGENT (ANALYSIS)
    # --------------------------------------------------

    async def rag_agent(self, state: AgentState) -> Dict[str, Any]:
        query = f"–ù–∞–≤—ã–∫–∏ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è {state['category']}"
        docs = self.vectorstore.similarity_search(query, k=5)
        context = "\n\n".join(d.page_content for d in docs)

        prompt = PromptTemplate(
            input_variables=["context"],
            template="""
–¢—ã –∫–∞—Ä—å–µ—Ä–Ω—ã–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç.

–ù–∞ –æ—Å–Ω–æ–≤–µ –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∏–∂–µ:
{context}

–°–¥–µ–ª–∞–π –∞–Ω–∞–ª–∏–∑:
1. –¢–û–ü-5 –Ω–∞–≤—ã–∫–æ–≤
2. –¢–∏–ø–∏—á–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
3. –ß—Ç–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤ —Ä–µ–∑—é–º–µ
4. –ö–∞–∫ –≤—ã–¥–µ–ª–∏—Ç—å—Å—è —Å—Ä–µ–¥–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤

–ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.
"""
        )

        res = await self.llm.ainvoke([
            HumanMessage(content=prompt.format(context=context))
        ])

        return {"rag_context": res.content}

    # --------------------------------------------------
    # FINAL
    # --------------------------------------------------

    async def finalize(self, state: AgentState) -> Dict[str, Any]:
        return {
            "confidence": {
                "hr": 0.9,
                "tech": 0.85,
                "market": 0.9
            },
            "processed": True
        }

    # --------------------------------------------------
    # API
    # --------------------------------------------------

    async def run(self, text: str) -> Dict[str, Any]:
        state: AgentState = {
            "description": text,
            "job_type": "",
            "search_type": "",
            "category": "",
            "hh_stats": {},
            "rag_context": "",
            "confidence": {},
            "processed": False
        }
        return await self.graph.ainvoke(state)

# ==================================================
# DEMO
# ==================================================

async def main():
    system = MultiAgentSystem()

    print("\nüß† GRAPH:")
    print(system.graph.get_graph().draw_mermaid())

    text = "–ò—â—É —Ä–∞–±–æ—Ç—É Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–º, –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç backend"
    result = await system.run(text)

    print("\nüìä HH –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(json.dumps(result["hh_stats"], ensure_ascii=False, indent=2))

    print("\nüß† RAG –ê–ù–ê–õ–ò–ó –†–´–ù–ö–ê:")
    print(result["rag_context"])

    print("\n‚úÖ –ì–û–¢–û–í–û. –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∞–Ω–∞–ª–∏–∑ –¥–ª—è —Ä–µ–∑—é–º–µ –∏ –æ—Ç–∫–ª–∏–∫–æ–≤.")

if __name__ == "__main__":
    asyncio.run(main())

#–≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ chroma —Å–æ–∑–¥–∞—Ç—å –∏ –≤—Å—Ç–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç, –∏–∑–º–µ–Ω–∏—Ç—å, —É–¥–∞–ª–∏—Ç—å –∏ –≤—ã–≤–µ—Å—Ç–∏ —Å–ø–∏—Å–æ–∫ –ø–æ —Å—Ç–∞—Ç—å–µ https://docs.trychroma.com/docs/overview/getting-started